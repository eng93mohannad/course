# المحولات , ماذا تفعل ؟ [[transformers-what-can-they-do]]
<CourseFloatingBanner chapter={1}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb"},
]} />

في هذا القسم ، سنلقي نظرة على ما يمكن أن تفعله نماذج المحولات ونستخدم أول أداة لدينا من مكتبة 🤗 Transformers اداة `pipeline ()`  
<Tip>
👀 انظر إلى الزر <em> فتح في Colab </em> في أعلى اليمين انقر فوقه لفتح دفتر الملاحظات Google Colab الذي يحتوي جميع نماذج التعليمات البرمجية لهذا القسم. تجد هذا الزر موجودًا في أي قسم يحتوي على أمثلة التعليمات البرمجية.

إذا كنت تريد تشغيل الأمثلة محليًا ، نوصي بإلقاء نظرة على <a href="/course/chapter 0"> الإعداد

 </a>.</Tip>

## المحولات في كل مكان ! [[transformers-are-everywhere]]

تُستخدم نماذج المحولات لحل جميع أنواع مهام معالجة اللغة الطبيعية، مثل تلك المذكورة في القسم السابق.
و فيما يلي بعض الشركات والمؤسسات التي تستخدم نماذج Hugging Face و Transformer ، والتي تساهم أيضًا بمشاركة نماذجها في المجتمع:
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG" alt="Companies using Hugging Face" width="100%">

[🤗 مكتبة المحولات](https://github.com/huggingface/transformers) يوفر وظائف لإنشاء واستخدام تلك النماذج المشتركة. [نموذج الـ Hub](https://huggingface.co/models) يحتوي على آلاف النماذج التي تم اختبارها مسبقًا والتي يمكن لأي شخص تنزيلها واستخدامها.
 يمكنك أيضًا رفع النماذج الخاصة بك إلى  HUP!
<Tip>
⚠️ لا يقتصر Hugging Face Hub على نماذج المحولات. يمكن لأي شخص مشاركة أي نوع من النماذج أو مجموعات البيانات التي يريدها! <a href="https://huggingface.co/join">عليك ان تنشئ حساب للاستفادة من كل المزايا المتاحة  huggingface.co</a> 
</Tip>

قبل الغوص في كيفية عمل نماذج المحولات ، دعنا نلقي نظرة على بعض الأمثلة حول كيف تستخدم المحولات لحل بعض مشكلات معالجة اللغة الطبيعية  NLPالمثيرة للاهتمام.
## العمل مع الـ Pipelines  [[working-with-pipelines]]

<Youtube id="tiZFewofSLM" />

🤗اهم العناصر في مكتبة المحولات هو مهمة `pipeline ()` حيث يربط اي نموذج بخطوات المعالجة السابقة و اللاحقة ، مما يسمح لنا بإدخال أي نص بشكل مباشر والحصول على إجابة واضحة:
```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

يمكننا حتى تمرير العديد من الجمل!
```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

بشكل تلقائي ، يحدد ال pipeline  هذا نموذجًا معينًا تم اختباره مسبقًا و تم ضبطه بدقة لتحليل المشاعر باللغة الإنجليزية. يتم تنزيل النموذج وتخزينه مؤقتًا عند إنشاء كائن `classifier` . و إذا أعدت تشغيل الأمر ، فسيتم استخدام النموذج المخزن مؤقتًا ولا داعي لتنزيل النموذج مرة أخرى.

هناك ثلاث خطوات رئيسية معنية عند تمرير بعض النصوص إلى pipeline  :
1. النص معالج بشكل منسق يمكن للنموذج فهمه. 
2. المدخلات المعالجة مسبقاً مرت بنجاح على النموذج. 
3. النتائج المتوقعة معالجة مسبقاً حتى يتم فهمها. 

بعض من  [المتاح  pipelines](https://huggingface.co/transformers/main_classes/pipelines.html) are:

- `feature-extraction` (الحصول على تمثيل متجه لنص)
- `fill-mask`
- `ner` (التعرف على الكيانات المسماة)
- `question-answering`
- `sentiment-analysis`
- `summarization`
- `text-generation`
- `translation`
- `zero-shot-classification`

دعونا نلقي نظرة على القليل منها ! 
## Zero-shot classification[[zero-shot-classification]]

سنبدأ بمعالجة مهمة أكثر صعوبة حيث نحتاج إلى تصنيف النصوص التي لم يتم تصنيفها. هذا سيناريو شائع في مشاريع العالم الحقيقي لأن كتابة التعليقات التوضيحية عادة ما تستغرق وقتًا طويلاً وتتطلب خبرة في المجال. بالنسبة لحالة الاستخدام هذه ، يعد `zero-shot-classification` pipeline  قويًا للغاية: فهو يسمح لك بتحديد المصنفات التي يجب استخدامها في التصنيف ، لذلك لا يتعين عليك الاعتماد على تسميات النموذج الذي تم اختباره مسبقًا. لقد رأيت بالفعل كيف يمكن للنموذج تصنيف جملة على أنها إيجابية أو سلبية باستخدام هاتين التسميتين - ولكن يمكنه أيضًا تصنيف النص باستخدام أي مجموعة أخرى من التسميات التي تريدها.
```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python out
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

يُطلق على خط الأنابيب هذا _zero-shot_  لأنك لست بحاجة إلى ضبط النموذج على بياناتك لاستخدامه. يمكنه إرجاع درجات الاحتمالية مباشرة لأي قائمة تسميات تريدها!
<Tip>

✏️ **جربها ** تلاعب بالتسلسلات والتصنيفات الخاصة بك وانظر كيف يتصرف النموذج.

</Tip>


## انشاء نص [[text-generation]]

الآن دعنا نرى كيفية استخدام pipeline لتوليد بعض النصوص. الفكرة الرئيسية هنا هي أنك تقدم مطالبة وسيقوم النموذج بإكمالها تلقائيًا عن طريق إنشاء النص المتبقي. هذا مشابه لميزة النص التنبئي الموجودة في العديد من الهواتف. يتضمن إنشاء النصوص العشوائية ، لذلك من الطبيعي ان لا تحصل على نفس النتائج كما هو موضح أدناه.
```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python out
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows — data flows of various types, as seen by the '
                    'HTTP'}]
```

يمكنك التحكم في عدد التسلسلات المختلفة التي يتم إنشاؤها باستخدام الوسيطة `num_return_sequences` والطول الإجمالي للنص الناتج باستخدام الوسيطة `max_length`.
<Tip>

✏️ **جربها !** استخدم الوسيطتين "`num_return_sequences`و `max_length` لإنشاء جملتين من 15 كلمة لكل منهما.

</Tip>


## استخدام أي نموذج من Hub في pipeline  [[using-any-model-from-the-hub-in-a-pipeline]]

استخدمت الأمثلة السابقة النموذج التلقائي للمهمة الموجودة معنا ، ولكن يمكنك أيضًا اختيار نموذج معين من Hub لاستخدامه في pipeline   لمهمة معينة - على سبيل المثال ، إنشاء نص. انتقل إلى [Model Hub] (https://huggingface.co/models) وانقر على العلامة المقابلة على اليسار لعرض النماذج المدعومة لهذه المهمة فقط. يجب أن تصل إلى صفحة مثل [هذه] (https://huggingface.co/models؟pipeline_tag=text-generation).
دعنا نجرب هذا النموذج[`distilgpt2`](https://huggingface.co/distilgpt2) ! هنا يمكنك رفعها في نفس pipeline  كما كان في السابق  :

```python
from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python out
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```
يمكنك تحسين البحث عن نموذج بالنقر فوق علامات اللغة واختيار نموذج يقوم بإنشاء نص بلغة أخرى. يحتوي Model Hub أيضًا على نقاط فحص لنماذج متعددة اللغات والتي تدعم عدة لغات مختلفة. 

بمجرد تحديد نموذج بالنقر فوقه ، سترى أن هناك عنصر واجهة مستخدم يمكنك من تجربته مباشرة عبر الإنترنت. بهذه الطريقة يمكنك اختبار إمكانيات النموذج بسرعة قبل تنزيله.
<Tip>

✏️ **جربها ! ** استخدم عوامل التصفية او الفلترة للعثور على نموذج إنشاء نص للغة أخرى. لا تتردد في تغيير القطعة واستخدامها في pipeline  !

</Tip>

### واجهة برمجة API [[the-inference-api]]
 
يمكن اختبار جميع النماذج مباشرة من خلال متصفحك باستخدام واجهة API Inference ، والمتاحة على موقع Hugging Face [موقع الويب] (https://huggingface.co/). يمكنك تعديل النموذج بشكل مباشر على هذه الصفحة عن طريق إدخال نص مخصص ومشاهدة النموذج وهو يعالج بيانات الإدخال.
تتوفر أيضًا واجهة API Inference ,التي تشغل هذه الأداة, كمنتج مدفوع ، والتي تكون مفيدة إذا احتجت إليها لسير العمل الخاص بك. راجع [صفحة الاسعار] (https://huggingface.co/pricing) للحصول على مزيد من التفاصيل.
## Mask filling[[mask-filling]]

الـ pipeline التالي الذي ستجربه هو `fill-mask`, فكرة هذه المهمة هي ملء الفراغات في نص معين:
```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python out
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

تتحكم الوسيطة `top_k` في عدد الاحتمالات التي تريد عرضها. لاحظ أن النموذج هنا يملأ كلمة `<mask>` الخاصة ، والتي يشار إليها غالبًا باسم * رمز القناع * او *mask token*. قد تحتوي نماذج  mask-filling الأخرى على رموز قناع مختلفة ، لذلك من الجيد دائمًا التحقق من الكلمة المناسبة عند استكشاف النماذج الأخرى. تتمثل إحدى طرق التحقق من ذلك في النظر إلى الكلمة المستخدمة في الأداة.
<Tip>

✏️ **جربها !** ابحث عن نموذج `bert-base-cased` على Hub وحدد كلمة القناع الخاصة به في أداة Inference API. ماذا يتوقع هذا النموذج للجملة في مثال `pipeline` أعلاه؟

</Tip>

## التعرف على كيان محدد [[named-entity-recognition]]

يعتبر التعرف على الكيان المُسمى (NER) مهمة, حيث يتعين على النموذج العثور على جزء من المدخلات النصية التي تتوافق مع كيانات مثل الأشخاص أو المواقع أو المؤسسات. لنلقي نظرة على المثال التالي:
```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

هنا حدد النموذج بشكل صحيح أن سيلفان هو شخص (PER) ، و Hugging Face منظمة (ORG) ، و Brooklyn موقع (LOC).

نمرر الخيار `grouped_entities = True` في وظيفة إنشاء pipeline لإخباره بإعادة تجميع أجزاء الجملة التي تتوافق مع نفس الكيان معًا: هنا النموذج الذي تم تجميعه بشكل صحيح" Hugging "و" Face "كمنظمة واحدة ، على الرغم من أن الاسم يتكون من كلمات متعددة. في الواقع ، كما سنرى في الفصل التالي ، فإن المعالجة المسبقة تقسم بعض الكلمات إلى أجزاء أصغر. على سبيل المثال ، يتم تقسيم "Sylvain" إلى أربع قطع: `S` و` ## yl` و` ## va` و` ## in`. في خطوة ما بعد المعالجة ، نجح خط الأنابيب في إعادة تجميع تلك القطع.
<Tip>

✏️ **جربها !** ابحث في Model Hub عن نموذج قادر على عمل علامات جزء من الكلام (عادةً ما يتم اختصاره كـ POS) باللغة الإنجليزية. ماذا يتوقع هذا النموذج للجملة في المثال أعلاه؟

</Tip>

## Question answering[[question-answering]]

`question-answering` يجيب pipeline على الأسئلة باستخدام معلومات من سياق معين:

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python out
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

لاحظ أن pipeline هنا يعمل عن طريق استخراج المعلومات من السياق المقدم ؛ و لا يولد الجواب.

## Summarization[[summarization]]

التلخيص او Summarization  هو مهمة اختزال النص إلى نص أقصر مع الاحتفاظ بجميع (أو معظم) الجوانب المهمة المشار إليها في النص. هذا مثال:
```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)
```

```python out
[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]
```
و كما هو الحال مع إنشاء النص ، يمكنك تحديد `max_length` أو `min_length` للنتيجة. 

## Translation[[translation]]

للترجمة ، يمكنك استخدام نموذج تلقائي إذا قمت بتوفير لغتين في اسم المهمة (مثل "translation_en_to_fr" `) ، ولكن أسهل طريقة هي اختيار النموذج الذي تريد استخدامه في [Model Hub] (https : //huggingface.co/models). 
سنحاول هنا الترجمة من الفرنسية إلى الإنجليزية:
```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python out
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

Like with text generation and summarization, you can specify a `max_length` or a `min_length` for the result.

<Tip>

✏️ **جربها !** ابحث عن نماذج الترجمة بلغات أخرى وحاول ترجمة الجملة السابقة إلى عدة لغات مختلفة.

</Tip>

الـ pipelines  المعروضة حتى الآن هي في الغالب لأغراض توضيحية. تمت برمجتها لأداء مهام محددة ولا يمكنها أداء أشكال مختلفة منها. في الفصل التالي ، ستتعرف على ما يوجد داخل وظيفة `pipeline()` وكيفية تخصيص سلوكها.
